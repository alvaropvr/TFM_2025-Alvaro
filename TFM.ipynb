{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8ea6b2-ca8c-4435-903e-3217128b99fc",
   "metadata": {},
   "source": [
    "<h1>TFM: CREANDO OBJETO SCREENPRO2<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd2da2-d87f-47a0-bc95-e7f995444c09",
   "metadata": {},
   "source": [
    "<h3>Ajustar formato de la librería<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d14e7-9d6b-4fa6-bdab-80a4f16520c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV sin nombres asignados\n",
    "library_path = \"./TFM_12O/TFM_previo/library.csv\"\n",
    "library = pd.read_csv(library_path, header=None)  # Cargar sin encabezado (header=None)\n",
    "\n",
    "# Asignar nombres a las columnas\n",
    "library.columns = ['target', 'sequence', 'sgID']\n",
    "\n",
    "# Verificar los cambios\n",
    "print(\"Columnas renombradas:\")\n",
    "print(library.head())\n",
    "\n",
    "# Guardar el archivo con las columnas renombradas\n",
    "output_path = \"./TFM_12O/TFM_previo/library_renamed.csv\"\n",
    "library.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo con columnas renombradas guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f38e43-9bdb-41b1-bdcc-93660d7bfd6a",
   "metadata": {},
   "source": [
    "<h1>GENERAR COUNTS CON SCREENPRO2<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b7aebf",
   "metadata": {},
   "source": [
    "!pip install numba==0.56.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc7635-bea6-487e-ba9f-238d5c40e011",
   "metadata": {},
   "source": [
    "```python\n",
    "%pip install ScreenPro2\n",
    "%pip install polars\n",
    "%pip install anndata\n",
    "%pip install biobear\n",
    "%pip install simple_colors\n",
    "%pip install pydeseq2\n",
    "%pip install scanpy\n",
    "%pip install adjustText\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b761b538",
   "metadata": {},
   "source": [
    "```python\n",
    "#Generación de counts con el script fastq_to_counts.py\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#Agregar el directorio './TFM_12O/code' al sys.path\n",
    "code_dir = os.path.abspath(\"./TFM_12O/code\")\n",
    "if code_dir not in sys.path:\n",
    "    sys.path.append(code_dir)\n",
    "\n",
    "patuS_dir = \"./TFM_12O/01.QC/PatuS_reads\"\n",
    "patuT_dir = \"./TFM_12O/01.QC/PatuT_reads\"\n",
    "\n",
    "def extract_samples(directory):\n",
    "    \"\"\"\n",
    "    Extrae los nombres completos de los archivos FASTQ, incluyendo la extensión .fastq.\n",
    "    \"\"\"\n",
    "    sample_ids = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".fastq.gz\"):  # Procesar solo archivos FASTQ\n",
    "            sample_ids.append(file_name.split(\".fastq.gz\")[0])  # Eliminar solo la extensión\n",
    "    return sample_ids\n",
    "\n",
    "#Extraer muestras de ambas carpetas\n",
    "patuS_samples = extract_samples(patuS_dir)\n",
    "patuT_samples = extract_samples(patuT_dir)\n",
    "\n",
    "#Importar el módulo\n",
    "from fastqgz_to_counts import parallelSeqFileToCountsParallel\n",
    "import multiprocessing\n",
    "\n",
    "fasta_output_dir = \"./TFM_12O/02.Counts/PatuT_reads/unaligned_fasta\"\n",
    "count_output_dir = \"./TFM_12O/02.Counts/PatuT_reads/counts\"\n",
    "\n",
    "#Generar listas para fastq_files, fasta_outputs y count_outputs con rutas completas\n",
    "fastq_files = [os.path.join(patuT_dir, f\"{sample}.fastq.gz\") for sample in patuT_samples]\n",
    "fasta_outputs = [os.path.join(fasta_output_dir, f\"{sample}_unaligned.fa\") for sample in patuT_samples]\n",
    "count_outputs = [os.path.join(count_output_dir, f\"{sample}.counts\") for sample in patuT_samples]\n",
    "\n",
    "#Archivo FASTA de la biblioteca\n",
    "library_fasta = \"./TFM_12O/TFM_previo/library_renamed.fasta\"\n",
    "\n",
    "#Parámetros adicionales\n",
    "start_index = None  # Índice inicial para recortar (opcional, None si no recortas)\n",
    "stop_index = None   # Índice final para recortar (opcional, None si no recortas)\n",
    "test_mode = False   # Cambiar a True para modo de prueba\n",
    "\n",
    "#Crear un pool de procesos para procesamiento paralelo\n",
    "pool = multiprocessing.Pool(processes=4)  # Cambia \"4\" al número de núcleos disponibles\n",
    "\n",
    "#Llamar a la función para procesar en paralelo\n",
    "results = parallelSeqFileToCountsParallel(\n",
    "    fastqGzFileNameList=fastq_files,\n",
    "    fastaFileNameList=fasta_outputs,\n",
    "    countFileNameList=count_outputs,\n",
    "    libraryFasta=library_fasta,\n",
    "    processPool=pool,\n",
    "    startIndex=start_index,\n",
    "    stopIndex=stop_index,\n",
    "    test=test_mode\n",
    ")\n",
    "\n",
    "#Cerrar el pool de procesos\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "#Mostrar resultados\n",
    "for result in results:\n",
    "    print(\"Archivo procesado:\", result[0])\n",
    "    print(\"Total de lecturas procesadas:\", result[1][0])\n",
    "    print(\"Total de lecturas alineadas:\", result[1][1])\n",
    "    print(\"Porcentaje de alineación:\", result[1][2], \"%\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f33ac",
   "metadata": {},
   "source": [
    "```python\n",
    "#Hay una lectura que era un singletone, lo rellenamos con 0 el R2 porque los R2 tienen alrededor de un 0,3% de mapeo, así que el error es mínimo.\n",
    "#Por lo visto, se desordenaron los sgRNAs en el archivo de conteos, así que vamos a reordenarlos según su R1, el resto deberian estar bien.\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo problemático y del archivo de referencia\n",
    "archivo_problematico = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\TFM_12O\\02.Counts\\scp2\\PatuS_reads\\counts\\PatuS-Cas9-14d-4_R2_trimmed.counts\"\n",
    "archivo_referencia = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\TFM_12O\\02.Counts\\scp2\\PatuS_reads\\counts\\PatuS-14d-1_R1_trimmed.counts\"\n",
    "\n",
    "# Leer referencia para obtener el orden correcto de sgRNAs\n",
    "sgRNAs_ref = pd.read_csv(archivo_referencia, sep=None, engine='python', header=None, usecols=[0])[0].tolist()\n",
    "\n",
    "# Leer archivo problemático\n",
    "df_prob = pd.read_csv(archivo_problematico, sep=None, engine='python', header=None, names=['sgRNA', 'count'])\n",
    "\n",
    "# Reordenar según la referencia\n",
    "df_prob_reordenado = df_prob.set_index('sgRNA').reindex(sgRNAs_ref).reset_index()\n",
    "\n",
    "# Sobreescribir el archivo original\n",
    "df_prob_reordenado.to_csv(archivo_problematico, sep='\\t', header=False, index=False)\n",
    "\n",
    "# Mostrar las primeras filas para comprobar\n",
    "print(df_prob_reordenado.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637077ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir la matriz de counts ordenada para PatuS y guardarla en un TSV\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Rutas\n",
    "counts_dir = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\TFM_12O\\02.Counts\\scp2\\PatuS_reads\\counts\"\n",
    "output_tsv = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\csv2\\PatuS_X.tsv\"\n",
    "library_path = r\"./TFM_12O/TFM_previo/library.csv\"\n",
    "\n",
    "orden_muestras = [\n",
    "    # PatuS-7d\n",
    "    \"PatuS-7d-1\", \"PatuS-7d-2\", \"PatuS-7d-3\", \"PatuS-7d-4\", \"PatuS-7d-5\",\n",
    "    # PatuS-14d\n",
    "    \"PatuS-14d-1\", \"PatuS-14d-2\", \"PatuS-14d-3\", \"PatuS-14d-4\", \"PatuS-14d-5\",\n",
    "    # PatuS-21d\n",
    "    \"PatuS-21d-1\", \"PatuS-21d-2\", \"PatuS-21d-3\", \"PatuS-21d-4\", \"PatuS-21d-5\",\n",
    "    # PatuS-Cas9-7d\n",
    "    \"PatuS-Cas9-7d-1\", \"PatuS-Cas9-7d-2\", \"PatuS-Cas9-7d-3\", \"PatuS-Cas9-7d-4\", \"PatuS-Cas9-7d-5\",\n",
    "    # PatuS-Cas9-14d\n",
    "    \"PatuS-Cas9-14d-1\", \"PatuS-Cas9-14d-2\", \"PatuS-Cas9-14d-3\", \"PatuS-Cas9-14d-4\", \"PatuS-Cas9-14d-5\",\n",
    "    # PatuS-Cas9-21d\n",
    "    \"PatuS-Cas9-21d-1\", \"PatuS-Cas9-21d-2\", \"PatuS-Cas9-21d-3\", \"PatuS-Cas9-21d-4\", \"PatuS-Cas9-21d-5\",\n",
    "    # pEPIGEN\n",
    "    \"pEPIGEN1\", \"pEPIGEN2\"\n",
    "]\n",
    "\n",
    "# Leer los sgRNAs del primer archivo R1 para fijar el orden inicial\n",
    "first_file = os.path.join(counts_dir, f\"{orden_muestras[0]}_R1_trimmed.counts\")\n",
    "sgRNAs = pd.read_csv(first_file, sep=None, engine='python', header=None, usecols=[0])[0].tolist()\n",
    "print(\"Orden de muestras (lecturas):\", orden_muestras)\n",
    "print(\"Número de sgRNAs:\", len(sgRNAs))\n",
    "\n",
    "all_counts = []\n",
    "\n",
    "for sample in orden_muestras:\n",
    "    r1_file = f\"{sample}_R1_trimmed.counts\"\n",
    "    r2_file = f\"{sample}_R2_trimmed.counts\"\n",
    "    r1_path = os.path.join(counts_dir, r1_file)\n",
    "    r2_path = os.path.join(counts_dir, r2_file)\n",
    "    df_r1 = pd.read_csv(r1_path, sep=None, engine='python', header=None, names=['sgRNA', 'count'])\n",
    "    df_r2 = pd.read_csv(r2_path, sep=None, engine='python', header=None, names=['sgRNA', 'count'])\n",
    "    df_r1 = df_r1.set_index('sgRNA').reindex(sgRNAs).fillna(0)\n",
    "    df_r2 = df_r2.set_index('sgRNA').reindex(sgRNAs).fillna(0)\n",
    "    summed = df_r1['count'].astype(int) + df_r2['count'].astype(int)\n",
    "    all_counts.append(summed.values)\n",
    "\n",
    "counts_df = pd.DataFrame(all_counts, columns=sgRNAs, index=orden_muestras)\n",
    "\n",
    "# --- REORDENAR sgRNAs SEGÚN LA LIBRERÍA DE REFERENCIA (ROBUSTO) ---\n",
    "library_df = pd.read_csv(library_path, header=None)\n",
    "# Limpiar nombres de sgRNAs en ambos lados\n",
    "sgRNA_order = [str(x).strip().replace('\\ufeff', '') for x in library_df[0].tolist()]\n",
    "counts_df.columns = [str(x).strip().replace('\\ufeff', '') for x in counts_df.columns]\n",
    "\n",
    "# Solo mantener y reordenar los sgRNAs que están en ambos\n",
    "sgRNAs_final = [sg for sg in sgRNA_order if sg in counts_df.columns]\n",
    "counts_df = counts_df[sgRNAs_final]\n",
    "\n",
    "# Guardar CSV con nombres de sgRNAs como encabezado y muestras como primera columna\n",
    "counts_df.index.name = \"sample\"\n",
    "counts_df.to_csv(output_tsv, sep='\\t')\n",
    "\n",
    "print(\"\\nControl final:\")\n",
    "print(\"Primeros sgRNAs (columnas):\", list(counts_df.columns[:5]))\n",
    "print(\"Primeras muestras (filas):\", list(counts_df.index[:5]))\n",
    "print(\"Shape:\", counts_df.shape)\n",
    "print(f\"Guardado: {output_tsv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir la matriz de counts ordenada para PatuT y guardarla en un TSV\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Rutas\n",
    "counts_dir_t = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\TFM_12O\\02.Counts\\scp2\\PatuT_reads\\counts\"\n",
    "output_tsv_t = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\csv2\\PatuT_X.tsv\"\n",
    "library_path_t = r\"./TFM_12O/TFM_previo/library.csv\"\n",
    "\n",
    "orden_muestras_t = [\n",
    "    # PatuT-7d\n",
    "    \"PatuT-7d-1\", \"PatuT-7d-2\", \"PatuT-7d-3\", \"PatuT-7d-4\", \"PatuT-7d-5\",\n",
    "    # PatuT-14d\n",
    "    \"PatuT-14d-1\", \"PatuT-14d-2\", \"PatuT-14d-3\", \"PatuT-14d-4\", \"PatuT-14d-5\",\n",
    "    # PatuT-21d\n",
    "    \"PatuT-21d-1\", \"PatuT-21d-2\", \"PatuT-21d-3\", \"PatuT-21d-4\", \"PatuT-21d-5\",\n",
    "    # PatuT-Cas9-7d\n",
    "    \"PatuT-Cas9-7d-1\", \"PatuT-Cas9-7d-2\", \"PatuT-Cas9-7d-3\", \"PatuT-Cas9-7d-4\", \"PatuT-Cas9-7d-5\",\n",
    "    # PatuT-Cas9-14d\n",
    "    \"PatuT-Cas9-14d-1\", \"PatuT-Cas9-14d-2\", \"PatuT-Cas9-14d-3\", \"PatuT-Cas9-14d-4\", \"PatuT-Cas9-14d-5\",\n",
    "    # PatuT-Cas9-21d\n",
    "    \"PatuT-Cas9-21d-1\", \"PatuT-Cas9-21d-2\", \"PatuT-Cas9-21d-3\", \"PatuT-Cas9-21d-4\", \"PatuT-Cas9-21d-5\",\n",
    "    # pEPIGEN\n",
    "    \"pEPIGEN1\", \"pEPIGEN2\"\n",
    "]\n",
    "\n",
    "# Leer los sgRNAs del primer archivo R1 para fijar el orden\n",
    "first_file_t = os.path.join(counts_dir_t, f\"{orden_muestras_t[0]}_R1_trimmed.counts\")\n",
    "sgRNAs_t = pd.read_csv(first_file_t, sep=None, engine='python', header=None, usecols=[0])[0].tolist()\n",
    "print(\"Orden de muestras (lecturas):\", orden_muestras_t)\n",
    "print(\"Número de sgRNAs:\", len(sgRNAs_t))\n",
    "\n",
    "all_counts_t = []\n",
    "\n",
    "for sample in orden_muestras_t:\n",
    "    r1_file = f\"{sample}_R1_trimmed.counts\"\n",
    "    r2_file = f\"{sample}_R2_trimmed.counts\"\n",
    "    r1_path = os.path.join(counts_dir_t, r1_file)\n",
    "    r2_path = os.path.join(counts_dir_t, r2_file)\n",
    "    df_r1 = pd.read_csv(r1_path, sep=None, engine='python', header=None, names=['sgRNA', 'count'])\n",
    "    df_r2 = pd.read_csv(r2_path, sep=None, engine='python', header=None, names=['sgRNA', 'count'])\n",
    "    df_r1 = df_r1.set_index('sgRNA').reindex(sgRNAs_t).fillna(0)\n",
    "    df_r2 = df_r2.set_index('sgRNA').reindex(sgRNAs_t).fillna(0)\n",
    "    summed = df_r1['count'].astype(int) + df_r2['count'].astype(int)\n",
    "    all_counts_t.append(summed.values)\n",
    "\n",
    "counts_df_t = pd.DataFrame(all_counts_t, columns=sgRNAs_t, index=orden_muestras_t)\n",
    "\n",
    "# --- REORDENAR sgRNAs SEGÚN LA LIBRERÍA DE REFERENCIA (ROBUSTO) ---\n",
    "library_df_t = pd.read_csv(library_path_t, header=None)\n",
    "# Usar la PRIMERA columna de la librería para el orden de sgRNAs\n",
    "sgRNA_order_t = [str(x).strip().replace('\\ufeff', '') for x in library_df_t[0].tolist()]\n",
    "counts_df_t.columns = [str(x).strip().replace('\\ufeff', '') for x in counts_df_t.columns]\n",
    "\n",
    "# Solo mantener y reordenar los sgRNAs que están en ambos\n",
    "sgRNAs_final_t = [sg for sg in sgRNA_order_t if sg in counts_df_t.columns]\n",
    "counts_df_t = counts_df_t[sgRNAs_final_t]\n",
    "\n",
    "# Guardar CSV con nombres de sgRNAs como encabezado y muestras como primera columna\n",
    "counts_df_t.index.name = \"sample\"\n",
    "counts_df_t.to_csv(output_tsv_t, sep='\\t')\n",
    "\n",
    "print(\"\\nControl final:\")\n",
    "print(\"Primeros sgRNAs (columnas):\", list(counts_df_t.columns[:5]))\n",
    "print(\"Primeras muestras (filas):\", list(counts_df_t.index[:5]))\n",
    "print(\"Shape:\", counts_df_t.shape)\n",
    "print(f\"Guardado: {output_tsv_t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd708cf5-f884-477c-a0bc-c725800ec60a",
   "metadata": {},
   "source": [
    "<h1>GENERAR OBJETO ANNDATA <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b9ba9",
   "metadata": {},
   "source": [
    "<H5> GENERAR ANNDATA.X <H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4015df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el anndata.X para PatuS y PatuT\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer la matriz de counts de PatuS (sin encabezados)\n",
    "counts_path_patuS = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\csv2\\PatuS_X.tsv\"\n",
    "counts_df_patuS = pd.read_csv(counts_path_patuS, sep='\\t', header=0, index_col=0)\n",
    "patuS_X = counts_df_patuS.values  # numpy array\n",
    "\n",
    "# Leer la matriz de counts de PatuT (sin encabezados)\n",
    "counts_path_patuT = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\csv2\\PatuT_X.tsv\"\n",
    "counts_df_patuT = pd.read_csv(counts_path_patuT, sep='\\t', header=0, index_col=0)\n",
    "patuT_X = counts_df_patuT.values  # numpy array\n",
    "\n",
    "print(\"Shape matriz PatuS:\", patuS_X.shape)\n",
    "print(\"Shape matriz PatuT:\", patuT_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275dae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el anndata.X para PatuS y PatuT con counts provenientes de mageckcount.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer la librería y obtener el orden correcto de sgRNAs (primera columna)\n",
    "library_path = \"./TFM_12O/TFM_previo/library.csv\"\n",
    "library_df = pd.read_csv(library_path, header=None)\n",
    "sgRNA_order = [str(x).strip().replace('\\ufeff', '') for x in library_df[0].tolist()]\n",
    "\n",
    "# PatuS\n",
    "file_path_s = r\"TFM_12O\\02.Counts\\mageckcount\\all_samples_PatuS.count.txt\"\n",
    "df_s = pd.read_csv(file_path_s, sep='\\t')\n",
    "df_s['sgRNA'] = df_s['sgRNA'].astype(str).str.strip().str.replace('\\ufeff', '', regex=False)\n",
    "df_s = df_s.set_index('sgRNA')\n",
    "sgRNAs_final = [sg for sg in sgRNA_order if sg in df_s.index]\n",
    "df_s = df_s.loc[sgRNAs_final]\n",
    "print(\"Primeros sgRNAs PatuS (ordenados):\", list(df_s.index[:5]))\n",
    "patuS_mageck_X = df_s.iloc[:, 1:].T.to_numpy()  # Omitir columna 'Gene'\n",
    "print(\"Shape matriz PatuS (muestras, sgRNAs):\", patuS_mageck_X.shape)\n",
    "\n",
    "# PatuT\n",
    "file_path_t = r\"TFM_12O\\02.Counts\\mageckcount\\all_samples_PatuT.count.txt\"\n",
    "df_t = pd.read_csv(file_path_t, sep='\\t')\n",
    "df_t['sgRNA'] = df_t['sgRNA'].astype(str).str.strip().str.replace('\\ufeff', '', regex=False)\n",
    "df_t = df_t.set_index('sgRNA')\n",
    "sgRNAs_final_t = [sg for sg in sgRNA_order if sg in df_t.index]\n",
    "df_t = df_t.loc[sgRNAs_final_t]\n",
    "print(\"Primeros sgRNAs PatuT (ordenados):\", list(df_t.index[:5]))\n",
    "patuT_mageck_X = df_t.iloc[:, 1:].T.to_numpy()\n",
    "print(\"Shape matriz PatuT (muestras, sgRNAs):\", patuT_mageck_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965edb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el anndata.X para PatuS con counts corregidos por CNV provenientes del script fastq_to_counts.py.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Definir el orden esperado de las muestras y sgRNAs\n",
    "orden_muestras_t = [\n",
    "    \"PatuS-7d-1\", \"PatuS-7d-2\", \"PatuS-7d-3\", \"PatuS-7d-4\", \"PatuS-7d-5\",\n",
    "    \"PatuS-14d-1\", \"PatuS-14d-2\", \"PatuS-14d-3\", \"PatuS-14d-4\", \"PatuS-14d-5\",\n",
    "    \"PatuS-21d-1\", \"PatuS-21d-2\", \"PatuS-21d-3\", \"PatuS-21d-4\", \"PatuS-21d-5\",\n",
    "    \"PatuS-Cas9-7d-1\", \"PatuS-Cas9-7d-2\", \"PatuS-Cas9-7d-3\", \"PatuS-Cas9-7d-4\", \"PatuS-Cas9-7d-5\",\n",
    "    \"PatuS-Cas9-14d-1\", \"PatuS-Cas9-14d-2\", \"PatuS-Cas9-14d-3\", \"PatuS-Cas9-14d-4\", \"PatuS-Cas9-14d-5\",\n",
    "    \"PatuS-Cas9-21d-1\", \"PatuS-Cas9-21d-2\", \"PatuS-Cas9-21d-3\", \"PatuS-Cas9-21d-4\", \"PatuS-Cas9-21d-5\",\n",
    "    \"pEPIGEN1\", \"pEPIGEN2\"\n",
    "]\n",
    "\n",
    "# Cargar el archivo de referencia de sgRNAs\n",
    "library = pd.read_csv(\"./TFM_12O/TFM_previo/library_renamed.csv\")\n",
    "orden_sgrnas = library['target'].astype(str).tolist()\n",
    "\n",
    "# Leer el archivo de counts asegurando que todo se carga como string\n",
    "counts = pd.read_csv(\"csv2/PatuS_CNVcorrected.tsv\", sep='\\t', dtype=str)\n",
    "\n",
    "# Establecer el índice por sgRNA y asegurar la presencia de los samples esperados\n",
    "counts = counts.set_index('sgRNA')\n",
    "counts = counts.loc[:, orden_muestras_t]  # Filtrar solo las columnas correctas\n",
    "\n",
    "# Asegurar el orden de los sgRNAs\n",
    "counts = counts.reindex(orden_sgrnas)\n",
    "\n",
    "# Puntos de control para confirmar orden correcto\n",
    "print(\"Chequeo de orden de samples:\")\n",
    "print(\"Esperado:\", orden_muestras_t)\n",
    "print(\"En la matriz:\", list(counts.columns))\n",
    "print(\"¿Coinciden?\", orden_muestras_t == list(counts.columns))\n",
    "print()\n",
    "\n",
    "print(\"Chequeo de orden de sgRNAs:\")\n",
    "print(\"Primeros 5 esperados:\", orden_sgrnas[:5])\n",
    "print(\"Primeros 5 en la matriz:\", list(counts.index[:5]))\n",
    "print(\"Últimos 5 esperados:\", orden_sgrnas[-5:])\n",
    "print(\"Últimos 5 en la matriz:\", list(counts.index[-5:]))\n",
    "print(\"¿Coinciden?\", orden_sgrnas == list(counts.index))\n",
    "print()\n",
    "\n",
    "# Convertir a numpy array eliminando encabezados y descriptoras\n",
    "counts = counts.astype(float).astype(int)  # Redondear y pasar a int\n",
    "PatuS_CNV_X = np.transpose(counts.values)  # Transponer para obtener el shape correcto (32, 1574)\n",
    "pd.DataFrame(PatuS_CNV_X).to_csv(\"csv2/PatuS_CNV_X.tsv\", sep='\\t', index=False, header=False, quoting=3)\n",
    "\n",
    "# Puntos de control finales\n",
    "print(\"Shape de PatuS_CNV_X:\", PatuS_CNV_X.shape)  # Esperado (32, 1574)\n",
    "print(\"Primeros valores:\\n\", PatuS_CNV_X[:5, :5])  # Verificación visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el anndata.X para PatuT con counts corregidos por CNV provenientes del script fastq_to_counts.py.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Definir el orden esperado de las muestras y sgRNAs\n",
    "orden_muestras_t = [\n",
    "    \"PatuT-7d-1\", \"PatuT-7d-2\", \"PatuT-7d-3\", \"PatuT-7d-4\", \"PatuT-7d-5\",\n",
    "    \"PatuT-14d-1\", \"PatuT-14d-2\", \"PatuT-14d-3\", \"PatuT-14d-4\", \"PatuT-14d-5\",\n",
    "    \"PatuT-21d-1\", \"PatuT-21d-2\", \"PatuT-21d-3\", \"PatuT-21d-4\", \"PatuT-21d-5\",\n",
    "    \"PatuT-Cas9-7d-1\", \"PatuT-Cas9-7d-2\", \"PatuT-Cas9-7d-3\", \"PatuT-Cas9-7d-4\", \"PatuT-Cas9-7d-5\",\n",
    "    \"PatuT-Cas9-14d-1\", \"PatuT-Cas9-14d-2\", \"PatuT-Cas9-14d-3\", \"PatuT-Cas9-14d-4\", \"PatuT-Cas9-14d-5\",\n",
    "    \"PatuT-Cas9-21d-1\", \"PatuT-Cas9-21d-2\", \"PatuT-Cas9-21d-3\", \"PatuT-Cas9-21d-4\", \"PatuT-Cas9-21d-5\",\n",
    "    \"pEPIGEN1\", \"pEPIGEN2\"\n",
    "]\n",
    "\n",
    "# Cargar el archivo de referencia de sgRNAs\n",
    "library = pd.read_csv(\"./TFM_12O/TFM_previo/library_renamed.csv\")\n",
    "orden_sgrnas = library['target'].astype(str).tolist()\n",
    "\n",
    "# Leer el archivo de counts asegurando que todo se carga como string\n",
    "counts = pd.read_csv(\"csv2/PatuT_CNVcorrected.tsv\", sep='\\t', dtype=str)\n",
    "\n",
    "# Establecer el índice por sgRNA y asegurar la presencia de los samples esperados\n",
    "counts = counts.set_index('sgRNA')\n",
    "counts = counts.loc[:, orden_muestras_t]  # Filtrar solo las columnas correctas\n",
    "\n",
    "# Asegurar el orden de los sgRNAs\n",
    "counts = counts.reindex(orden_sgrnas)\n",
    "\n",
    "# Puntos de control para confirmar orden correcto\n",
    "print(\"Chequeo de orden de samples:\")\n",
    "print(\"Esperado:\", orden_muestras_t)\n",
    "print(\"En la matriz:\", list(counts.columns))\n",
    "print(\"¿Coinciden?\", orden_muestras_t == list(counts.columns))\n",
    "print()\n",
    "\n",
    "print(\"Chequeo de orden de sgRNAs:\")\n",
    "print(\"Primeros 5 esperados:\", orden_sgrnas[:5])\n",
    "print(\"Primeros 5 en la matriz:\", list(counts.index[:5]))\n",
    "print(\"Últimos 5 esperados:\", orden_sgrnas[-5:])\n",
    "print(\"Últimos 5 en la matriz:\", list(counts.index[-5:]))\n",
    "print(\"¿Coinciden?\", orden_sgrnas == list(counts.index))\n",
    "print()\n",
    "\n",
    "# Convertir a numpy array eliminando encabezados y descriptoras\n",
    "counts = counts.astype(float).astype(int)  # Redondear y pasar a int\n",
    "PatuT_CNV_X = np.transpose(counts.values)  # Transponer para obtener el shape correcto (32, 1574)\n",
    "pd.DataFrame(PatuT_CNV_X).to_csv(\"csv2/PatuT_CNV_X.tsv\", sep='\\t', index=False, header=False, quoting=3)\n",
    "\n",
    "# Puntos de control finales\n",
    "print(\"Shape de PatuT_CNV_X:\", PatuT_CNV_X.shape)  # Esperado (32, 1574)\n",
    "print(\"Primeros valores:\\n\", PatuT_CNV_X[:5, :5])  # Verificación visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el anndata.X para PatuS con counts corregidos por CNV provenientes de mageckcount.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Definir el orden esperado de las muestras y sgRNAs para PatuS\n",
    "orden_muestras_s = [\n",
    "    \"PatuS-7d-1\", \"PatuS-7d-2\", \"PatuS-7d-3\", \"PatuS-7d-4\", \"PatuS-7d-5\",\n",
    "    \"PatuS-14d-1\", \"PatuS-14d-2\", \"PatuS-14d-3\", \"PatuS-14d-4\", \"PatuS-14d-5\",\n",
    "    \"PatuS-21d-1\", \"PatuS-21d-2\", \"PatuS-21d-3\", \"PatuS-21d-4\", \"PatuS-21d-5\",\n",
    "    \"PatuS-Cas9-7d-1\", \"PatuS-Cas9-7d-2\", \"PatuS-Cas9-7d-3\", \"PatuS-Cas9-7d-4\", \"PatuS-Cas9-7d-5\",\n",
    "    \"PatuS-Cas9-14d-1\", \"PatuS-Cas9-14d-2\", \"PatuS-Cas9-14d-3\", \"PatuS-Cas9-14d-4\", \"PatuS-Cas9-14d-5\",\n",
    "    \"PatuS-Cas9-21d-1\", \"PatuS-Cas9-21d-2\", \"PatuS-Cas9-21d-3\", \"PatuS-Cas9-21d-4\", \"PatuS-Cas9-21d-5\",\n",
    "    \"pEPIGEN1\", \"pEPIGEN2\"\n",
    "]\n",
    "\n",
    "# Cargar el archivo de referencia de sgRNAs\n",
    "library = pd.read_csv(\"./TFM_12O/TFM_previo/library_renamed.csv\")\n",
    "orden_sgrnas = library['target'].astype(str).tolist()\n",
    "\n",
    "# Leer el archivo de counts asegurando que todo se carga como string\n",
    "counts = pd.read_csv(\"csv2/PatuS_mageck_CNVcorrected.tsv\", sep='\\t', dtype=str)\n",
    "\n",
    "# Limpiar nombres de sgRNAs y columnas\n",
    "counts['sgRNA'] = counts['sgRNA'].astype(str).str.strip().replace('\\ufeff', '', regex=True)\n",
    "counts.columns = [str(col).strip().replace('\\ufeff', '') for col in counts.columns]\n",
    "\n",
    "# Establecer el índice por sgRNA\n",
    "counts = counts.set_index('sgRNA')\n",
    "\n",
    "# Solo mantener muestras y sgRNAs presentes en ambos lados (sin NAs)\n",
    "samples_final = [s for s in orden_muestras_s if s in counts.columns]\n",
    "sgRNAs_final = [sg for sg in orden_sgrnas if sg in counts.index]\n",
    "\n",
    "counts = counts.loc[sgRNAs_final, samples_final]\n",
    "\n",
    "# Puntos de control para confirmar orden correcto\n",
    "print(\"Chequeo de orden de samples:\")\n",
    "print(\"Esperado:\", samples_final)\n",
    "print(\"En la matriz:\", list(counts.columns))\n",
    "print(\"¿Coinciden?\", samples_final == list(counts.columns))\n",
    "print()\n",
    "\n",
    "print(\"Chequeo de orden de sgRNAs:\")\n",
    "print(\"Primeros 5 esperados:\", sgRNAs_final[:5])\n",
    "print(\"Primeros 5 en la matriz:\", list(counts.index[:5]))\n",
    "print(\"Últimos 5 esperados:\", sgRNAs_final[-5:])\n",
    "print(\"Últimos 5 en la matriz:\", list(counts.index[-5:]))\n",
    "print(\"¿Coinciden?\", sgRNAs_final == list(counts.index))\n",
    "print()\n",
    "\n",
    "# Convertir a numpy array eliminando encabezados y descriptoras\n",
    "counts = counts.astype(float).astype(int)  # Redondear y pasar a int\n",
    "PatuS_mageck_CNV_X = np.transpose(counts.values)  # (n_samples, n_sgRNAs)\n",
    "pd.DataFrame(PatuS_mageck_CNV_X).to_csv(\"csv2/PatuS_mageck_CNV_X.tsv\", sep='\\t', index=False, header=False, quoting=3)\n",
    "\n",
    "# Puntos de control finales\n",
    "print(\"Shape de PatuS_mageck_CNV_X:\", PatuS_mageck_CNV_X.shape)\n",
    "print(\"Primeros valores:\\n\", PatuS_mageck_CNV_X[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el anndata.X para PatuT con counts corregidos por CNV provenientes de mageckcount.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Definir el orden esperado de las muestras y sgRNAs\n",
    "orden_muestras_t = [\n",
    "    \"PatuT-7d-1\", \"PatuT-7d-2\", \"PatuT-7d-3\", \"PatuT-7d-4\", \"PatuT-7d-5\",\n",
    "    \"PatuT-14d-1\", \"PatuT-14d-2\", \"PatuT-14d-3\", \"PatuT-14d-4\", \"PatuT-14d-5\",\n",
    "    \"PatuT-21d-1\", \"PatuT-21d-2\", \"PatuT-21d-3\", \"PatuT-21d-4\", \"PatuT-21d-5\",\n",
    "    \"PatuT-Cas9-7d-1\", \"PatuT-Cas9-7d-2\", \"PatuT-Cas9-7d-3\", \"PatuT-Cas9-7d-4\", \"PatuT-Cas9-7d-5\",\n",
    "    \"PatuT-Cas9-14d-1\", \"PatuT-Cas9-14d-2\", \"PatuT-Cas9-14d-3\", \"PatuT-Cas9-14d-4\", \"PatuT-Cas9-14d-5\",\n",
    "    \"PatuT-Cas9-21d-1\", \"PatuT-Cas9-21d-2\", \"PatuT-Cas9-21d-3\", \"PatuT-Cas9-21d-4\", \"PatuT-Cas9-21d-5\",\n",
    "    \"pEPIGEN1\", \"pEPIGEN2\"\n",
    "]\n",
    "\n",
    "# Cargar el archivo de referencia de sgRNAs\n",
    "library = pd.read_csv(\"./TFM_12O/TFM_previo/library_renamed.csv\")\n",
    "orden_sgrnas = library['target'].astype(str).tolist()\n",
    "\n",
    "# Leer el archivo de counts asegurando que todo se carga como string\n",
    "counts = pd.read_csv(\"csv2/PatuT_mageck_CNVcorrected.tsv\", sep='\\t', dtype=str)\n",
    "\n",
    "# Limpiar nombres de sgRNAs y columnas\n",
    "counts['sgRNA'] = counts['sgRNA'].astype(str).str.strip().replace('\\ufeff', '', regex=True)\n",
    "counts.columns = [str(col).strip().replace('\\ufeff', '') for col in counts.columns]\n",
    "\n",
    "# Establecer el índice por sgRNA\n",
    "counts = counts.set_index('sgRNA')\n",
    "\n",
    "# Solo mantener muestras y sgRNAs presentes en ambos lados (sin NAs)\n",
    "samples_final = [s for s in orden_muestras_t if s in counts.columns]\n",
    "sgRNAs_final = [sg for sg in orden_sgrnas if sg in counts.index]\n",
    "\n",
    "counts = counts.loc[sgRNAs_final, samples_final]\n",
    "\n",
    "# Puntos de control para confirmar orden correcto\n",
    "print(\"Chequeo de orden de samples:\")\n",
    "print(\"Esperado:\", samples_final)\n",
    "print(\"En la matriz:\", list(counts.columns))\n",
    "print(\"¿Coinciden?\", samples_final == list(counts.columns))\n",
    "print()\n",
    "\n",
    "print(\"Chequeo de orden de sgRNAs:\")\n",
    "print(\"Primeros 5 esperados:\", sgRNAs_final[:5])\n",
    "print(\"Primeros 5 en la matriz:\", list(counts.index[:5]))\n",
    "print(\"Últimos 5 esperados:\", sgRNAs_final[-5:])\n",
    "print(\"Últimos 5 en la matriz:\", list(counts.index[-5:]))\n",
    "print(\"¿Coinciden?\", sgRNAs_final == list(counts.index))\n",
    "print()\n",
    "\n",
    "# Convertir a numpy array eliminando encabezados y descriptoras\n",
    "counts = counts.astype(float).astype(int)  # Redondear y pasar a int\n",
    "PatuT_mageck_CNV_X = np.transpose(counts.values)  # (n_samples, n_sgRNAs)\n",
    "pd.DataFrame(PatuT_mageck_CNV_X).to_csv(\"csv2/PatuT_mageck_CNV_X.tsv\", sep='\\t', index=False, header=False, quoting=3)\n",
    "\n",
    "# Puntos de control finales\n",
    "print(\"Shape de PatuT_mageck_CNV_X:\", PatuT_mageck_CNV_X.shape)\n",
    "print(\"Primeros valores:\\n\", PatuT_mageck_CNV_X[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b9ad6",
   "metadata": {},
   "source": [
    "<H5> GENERAR ANNDATA.OBS <H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4477b90-3755-40c3-bdb4-f684d1bab40c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista de muestras finales \n",
    "final_samples = [\n",
    "    \"PatuS-7d-1\", \"PatuS-7d-2\", \"PatuS-7d-3\", \"PatuS-7d-4\", \"PatuS-7d-5\",\n",
    "    \"PatuS-14d-1\", \"PatuS-14d-2\", \"PatuS-14d-3\", \"PatuS-14d-4\", \"PatuS-14d-5\",\n",
    "    \"PatuS-21d-1\", \"PatuS-21d-2\", \"PatuS-21d-3\", \"PatuS-21d-4\", \"PatuS-21d-5\",\n",
    "    \"PatuS-Cas9-7d-1\", \"PatuS-Cas9-7d-2\", \"PatuS-Cas9-7d-3\", \"PatuS-Cas9-7d-4\", \"PatuS-Cas9-7d-5\",\n",
    "    \"PatuS-Cas9-14d-1\", \"PatuS-Cas9-14d-2\", \"PatuS-Cas9-14d-3\", \"PatuS-Cas9-14d-4\", \"PatuS-Cas9-14d-5\",\n",
    "    \"PatuS-Cas9-21d-1\", \"PatuS-Cas9-21d-2\", \"PatuS-Cas9-21d-3\", \"PatuS-Cas9-21d-4\", \"PatuS-Cas9-21d-5\",\n",
    "    \"pEPIGEN1\", \"pEPIGEN2\"\n",
    "]\n",
    "\n",
    "# Crear DataFrame meta solo con las muestras finales\n",
    "meta_df_patuS = pd.DataFrame({\"sample_name\": final_samples})\n",
    "\n",
    "# Asignar la columna 'condition' según tu criterio\n",
    "def assign_condition(name):\n",
    "    if \"Cas9\" in name:\n",
    "        return \"treated\"\n",
    "    else:\n",
    "        return \"control\"\n",
    "\n",
    "meta_df_patuS[\"condition\"] = meta_df_patuS[\"sample_name\"].apply(assign_condition)\n",
    "\n",
    "# Extraer el número de replicado\n",
    "def extract_replicate(sample_name):\n",
    "    parts = sample_name.split(\"-\")\n",
    "    if \"Cas9\" in parts:  # Caso de muestras con 'Cas9'\n",
    "        return int(parts[3].split(\"_\")[0])\n",
    "    elif \"pEPIGEN\" in sample_name:  # Caso de controles 'pEPIGEN'\n",
    "        return int(sample_name.split(\"pEPIGEN\")[1].split(\"_\")[0])\n",
    "    else:  # Otros casos\n",
    "        return int(parts[2].split(\"_\")[0])\n",
    "\n",
    "meta_df_patuS[\"replicate\"] = meta_df_patuS[\"sample_name\"].apply(extract_replicate)\n",
    "\n",
    "print(meta_df_patuS)\n",
    "print(\"Shape de la matriz de counts:\", meta_df_patuS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista de muestras finales \n",
    "final_samples_patuT = [\n",
    "    \"PatuT-7d-1\", \"PatuT-7d-2\", \"PatuT-7d-3\", \"PatuT-7d-4\", \"PatuT-7d-5\",\n",
    "    \"PatuT-14d-1\", \"PatuT-14d-2\", \"PatuT-14d-3\", \"PatuT-14d-4\", \"PatuT-14d-5\",\n",
    "    \"PatuT-21d-1\", \"PatuT-21d-2\", \"PatuT-21d-3\", \"PatuT-21d-4\", \"PatuT-21d-5\",\n",
    "    \"PatuT-Cas9-7d-1\", \"PatuT-Cas9-7d-2\", \"PatuT-Cas9-7d-3\", \"PatuT-Cas9-7d-4\", \"PatuT-Cas9-7d-5\",\n",
    "    \"PatuT-Cas9-14d-1\", \"PatuT-Cas9-14d-2\", \"PatuT-Cas9-14d-3\", \"PatuT-Cas9-14d-4\", \"PatuT-Cas9-14d-5\",\n",
    "    \"PatuT-Cas9-21d-1\", \"PatuT-Cas9-21d-2\", \"PatuT-Cas9-21d-3\", \"PatuT-Cas9-21d-4\", \"PatuT-Cas9-21d-5\",\n",
    "    \"pEPIGEN1\", \"pEPIGEN2\"\n",
    "]\n",
    "\n",
    "# Crear DataFrame meta solo con las muestras finales de PatuT\n",
    "meta_df_patuT = pd.DataFrame({\"sample_name\": final_samples_patuT})\n",
    "\n",
    "# Asignar la columna 'condition' según tu criterio\n",
    "def assign_condition(name):\n",
    "    if \"Cas9\" in name:\n",
    "        return \"treated\"\n",
    "    else:\n",
    "        return \"control\"\n",
    "\n",
    "meta_df_patuT[\"condition\"] = meta_df_patuT[\"sample_name\"].apply(assign_condition)\n",
    "\n",
    "# Extraer el número de replicado\n",
    "def extract_replicate(sample_name):\n",
    "    parts = sample_name.split(\"-\")\n",
    "    if \"Cas9\" in parts:  # Caso de muestras con 'Cas9'\n",
    "        return int(parts[3].split(\"_\")[0])\n",
    "    elif \"pEPIGEN\" in sample_name:  # Caso de controles 'pEPIGEN'\n",
    "        return int(sample_name.split(\"pEPIGEN\")[1].split(\"_\")[0])\n",
    "    else:  # Otros casos\n",
    "        return int(parts[2].split(\"_\")[0])\n",
    "\n",
    "meta_df_patuT[\"replicate\"] = meta_df_patuT[\"sample_name\"].apply(extract_replicate)\n",
    "\n",
    "print(meta_df_patuT)\n",
    "print(\"Shape de la matriz de counts:\", meta_df_patuT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c010d",
   "metadata": {},
   "source": [
    "<H5> GENERAR EL ANNDATA.VAR <H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5087f-65fe-49e4-9074-16bff6ed1122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generar el df target_df_patuS\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar la librería\n",
    "library_renamed_path = \"./TFM_12O/TFM_previo/library_renamed.csv\"\n",
    "library_df = pd.read_csv(library_renamed_path)\n",
    "\n",
    "# Fusionar sgID y target en una sola columna \"target\" con formato \"sgID -> target\"\n",
    "library_df[\"target\"] = library_df[\"sgID\"].astype(str) + \" -> \" + library_df[\"target\"].astype(str)\n",
    "\n",
    "# Leer el archivo de controles negativos (un target por línea, sin cabecera)\n",
    "neg_ctrl_path = \"./TFM_12O/TFM_previo/PatuS_neg_controls_guides.txt\"\n",
    "with open(neg_ctrl_path, \"r\") as f:\n",
    "    negative_controls = set(line.strip() for line in f if line.strip())\n",
    "\n",
    "# Asignar targetType: \"negative_control\" si el target original está en la lista, si no \"experimental\"\n",
    "library_df[\"targetType\"] = library_df[\"target\"].apply(\n",
    "    lambda x: \"negative_control\" if x.split(\" -> \")[1] in negative_controls else \"experimental\"\n",
    ")\n",
    "\n",
    "# Crear el DataFrame final solo con las columnas necesarias\n",
    "target_df_patuS = library_df[[\"target\", \"targetType\"]].copy()\n",
    "\n",
    "# Guardar el DataFrame target_df como un archivo .tsv en la carpeta csv2\n",
    "\n",
    "output_target_tsv = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\csv2\\target_df_patuS.tsv\"\n",
    "target_df_patuS.to_csv(output_target_tsv, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Archivo guardado en: {output_target_tsv}\")\n",
    "print(\"Shape de target_df:\", target_df_patuS.shape)\n",
    "print(\"Primeros 5 targets:\", target_df_patuS.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20283381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el df target_df_patuT\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar la librería\n",
    "library_renamed_path = \"./TFM_12O/TFM_previo/library_renamed.csv\"\n",
    "library_df = pd.read_csv(library_renamed_path)\n",
    "\n",
    "# Fusionar sgID y target en una sola columna \"target\" con formato \"sgID -> target\"\n",
    "library_df[\"target\"] = library_df[\"sgID\"].astype(str) + \" -> \" + library_df[\"target\"].astype(str)\n",
    "\n",
    "# Leer el archivo de controles negativos (un target por línea, sin cabecera)\n",
    "neg_ctrl_path = \"./TFM_12O/TFM_previo/PatuT_neg_controls_guides.txt\"\n",
    "with open(neg_ctrl_path, \"r\") as f:\n",
    "    negative_controls = set(line.strip() for line in f if line.strip())\n",
    "\n",
    "# Asignar targetType: \"negative_control\" si el target original está en la lista, si no \"experimental\"\n",
    "library_df[\"targetType\"] = library_df[\"target\"].apply(\n",
    "    lambda x: \"negative_control\" if x.split(\" -> \")[1] in negative_controls else \"experimental\"\n",
    ")\n",
    "\n",
    "# Crear el DataFrame final solo con las columnas necesarias\n",
    "target_df_patuT = library_df[[\"target\", \"targetType\"]].copy()\n",
    "\n",
    "# Guardar el DataFrame target_df como un archivo .tsv en la carpeta csv2\n",
    "\n",
    "output_target_tsv = r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\csv2\\target_df_patuT.tsv\"\n",
    "target_df_patuT.to_csv(output_target_tsv, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Archivo guardado en: {output_target_tsv}\")\n",
    "print(\"Shape de target_df:\", target_df_patuT.shape)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ba033",
   "metadata": {},
   "source": [
    "<H5> CREACIÓN DEL OBJETO ANNDATA <H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c6398-e90a-44cd-81e2-989697de2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PatuS + Counts fastq_to_counts.py\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from screenpro.assays import PooledScreens\n",
    "\n",
    "patuS_adata = ad.AnnData(\n",
    "    X   = patuS_X, # pandas dataframe of counts (samples x targets)\n",
    "    obs = meta_df_patuS,   # pandas dataframe of samples metadata including \"condition\" and \"replicate\" columns\n",
    "    var = target_df_patuS  # pandas dataframe of targets metadata including \"target\" and \"targetType\" columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020f572-b179-4c2e-912f-d1fd33565ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PatuT + Counts fastq_to_counts.py\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from screenpro.assays import PooledScreens\n",
    "\n",
    "patuT_adata = ad.AnnData(\n",
    "    X   = patuT_X, # pandas dataframe of counts (samples x targets)\n",
    "    obs = meta_df_patuT,   # pandas dataframe of samples metadata including \"condition\" and \"replicate\" columns\n",
    "    var = target_df_patuT  # pandas dataframe of targets metadata including \"target\" and \"targetType\" columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PatuS + Counts mageckcount\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from screenpro.assays import PooledScreens\n",
    "\n",
    "patuS_mageck_adata = ad.AnnData(\n",
    "    X   = patuS_mageck_X, # pandas dataframe of counts (samples x targets)\n",
    "    obs = meta_df_patuS,   # pandas dataframe of samples metadata including \"condition\" and \"replicate\" columns\n",
    "    var = target_df_patuS  # pandas dataframe of targets metadata including \"target\" and \"targetType\" columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ed20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patuT + Counts mageckcount\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from screenpro.assays import PooledScreens\n",
    "\n",
    "patuT_mageck_adata = ad.AnnData(\n",
    "    X   = patuT_mageck_X, # pandas dataframe of counts (samples x targets)\n",
    "    obs = meta_df_patuT,   # pandas dataframe of samples metadata including \"condition\" and \"replicate\" columns\n",
    "    var = target_df_patuT  # pandas dataframe of targets metadata including \"target\" and \"targetType\" columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf857daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PatuS + counts fastq_to_counts.py corregidos por CNV\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from screenpro.assays import PooledScreens\n",
    "\n",
    "patuS_CNV_adata = ad.AnnData(\n",
    "    X   = PatuS_CNV_X, # pandas dataframe of counts (samples x targets)\n",
    "    obs = meta_df_patuS,   # pandas dataframe of samples metadata including \"condition\" and \"replicate\" columns\n",
    "    var = target_df_patuS  # pandas dataframe of targets metadata including \"target\" and \"targetType\" columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PatuT + counts fastq_to_counts.py corregidos por CNV\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from screenpro.assays import PooledScreens\n",
    "\n",
    "patuT_CNV_adata = ad.AnnData(\n",
    "    X   = PatuT_CNV_X, # pandas dataframe of counts (samples x targets)\n",
    "    obs = meta_df_patuT,   # pandas dataframe of samples metadata including \"condition\" and \"replicate\" columns\n",
    "    var = target_df_patuT  # pandas dataframe of targets metadata including \"target\" and \"targetType\" columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd95d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PatuS + counts mageckcount corregidos por CNV\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from screenpro.assays import PooledScreens\n",
    "\n",
    "patuS_mageck_CNV_adata = ad.AnnData(\n",
    "    X   = PatuS_mageck_CNV_X, # pandas dataframe of counts (samples x targets)\n",
    "    obs = meta_df_patuS,   # pandas dataframe of samples metadata including \"condition\" and \"replicate\" columns\n",
    "    var = target_df_patuS  # pandas dataframe of targets metadata including \"target\" and \"targetType\" columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d213c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PatuT + counts mageckcount corregidos por CNV\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from screenpro.assays import PooledScreens\n",
    "\n",
    "patuT_mageck_CNV_adata = ad.AnnData(\n",
    "    X   = PatuT_mageck_CNV_X, # pandas dataframe of counts (samples x targets)\n",
    "    obs = meta_df_patuT,   # pandas dataframe of samples metadata including \"condition\" and \"replicate\" columns\n",
    "    var = target_df_patuT  # pandas dataframe of targets metadata including \"target\" and \"targetType\" columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ca242",
   "metadata": {},
   "source": [
    "<H3> CÁLCULO DEL FENOTIPO <H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304ad7e",
   "metadata": {},
   "source": [
    "<H5> PATUS CORREGIDO POR CNV ANNDATA<H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from screenpro.phenoscore import runPhenoScore\n",
    "\n",
    "result_name, result_df_patuS_CNV = runPhenoScore(\n",
    "    adata=patuS_CNV_adata,\n",
    "    cond_ref=\"control\",\n",
    "    cond_test=\"treated\",\n",
    "    score_level=\"compare_reps\",\n",
    "    var_names=\"target\",\n",
    "    test=\"ttest\",\n",
    "    ctrl_label=\"negative_control\"\n",
    ")\n",
    "\n",
    "# Mostrar los primeros resultados obtenidos\n",
    "print(f\"Resultados guardados bajo el nombre: {result_name}\")\n",
    "print(result_df_patuS_CNV.head())\n",
    "\n",
    "# Filtrar e imprimir todos los resultados significativos (BH adj_pvalue <= 0.05)\n",
    "significativos = result_df_patuS_CNV[result_df_patuS_CNV[\"BH adj_pvalue\"] <= 0.05]\n",
    "print(f\"Resultados significativos (BH adj_pvalue <= 0.05): {len(significativos)}\")\n",
    "print(significativos)\n",
    "\n",
    "# Volcano plot para result_df_patuS (score vs. -log10(ttest pvalue)), resaltando sgRNAs con |score| ≥ 0.15 y ttest pvalue < 0.05\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "df = result_df_patuS_CNV.copy()\n",
    "df['-log10_ttest_pvalue'] = -np.log10(df['ttest pvalue'])\n",
    "is_significant = (df['ttest pvalue'] < 0.05) & (np.abs(df['score']) >= 0.15)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.scatter(df['score'], df['-log10_ttest_pvalue'], c='grey', alpha=0.5, label='Not significant')\n",
    "plt.scatter(df[is_significant]['score'], df[is_significant]['-log10_ttest_pvalue'],\n",
    "            c='red', alpha=0.8, label='Significant (|score| ≥ 0.15 & ttest pvalue < 0.05)')\n",
    "\n",
    "# Etiquetas bonitas con adjustText\n",
    "texts = []\n",
    "for _, row in df[is_significant].iterrows():\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['score'], row['-log10_ttest_pvalue'],\n",
    "            str(row['target']),\n",
    "            fontsize=10, color='black', weight='bold',\n",
    "            bbox=dict(facecolor='white', edgecolor='red', boxstyle='round,pad=0.2'),\n",
    "            ha='left', va='center'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Ajustar las etiquetas para que no se salgan ni se solapen\n",
    "adjust_text(\n",
    "    texts,\n",
    "    only_move={'points':'y', 'texts':'y'},  # Solo mover en vertical\n",
    "    arrowprops=dict(arrowstyle='-', color='red', lw=1)\n",
    ")\n",
    "\n",
    "plt.axvline(x=0.15, color='blue', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=-0.15, color='blue', linestyle='--', linewidth=1)\n",
    "plt.axhline(y=-np.log10(0.05), color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Phenotype Score')\n",
    "plt.ylabel('-log10(pvalue)')\n",
    "plt.title('Volcano plot PatuS')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ranked phenotype score plot for PatuS corrected by CNV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# 1. Prepare data\n",
    "df = result_df_patuS_CNV.copy()\n",
    "df = df.dropna(subset=['score', 'BH adj_pvalue'])\n",
    "df['gene'] = df['target'].str.split('--?>').str[0].str.strip()\n",
    "df['-log10_pval'] = -np.log10(np.clip(df['BH adj_pvalue'], 1e-300, 1))\n",
    "\n",
    "# 2. Sort by score for global ranking\n",
    "df = df.sort_values('score')\n",
    "df = df.reset_index(drop=True)\n",
    "df['rank'] = np.arange(1, len(df)+1)\n",
    "\n",
    "# 3. Find lowest and highest score for each gene\n",
    "idx_min = df.groupby('gene')['score'].idxmin()\n",
    "idx_max = df.groupby('gene')['score'].idxmax()\n",
    "extremos = pd.concat([df.loc[idx_min], df.loc[idx_max]]).drop_duplicates()\n",
    "\n",
    "# 4. Select 10 depleted genes and 10 enriched genes\n",
    "top_depleted = extremos.nsmallest(10, 'score')  # 10 depleted\n",
    "top_enriched = extremos.nlargest(10, 'score')   # 10 enriched\n",
    "idx_to_label = set(top_depleted.index).union(set(top_enriched.index))\n",
    "\n",
    "# 5. Color and size\n",
    "colors = np.where(df['score'] < 0, '#1f77b4', '#d62728')\n",
    "sizes = np.interp(df['-log10_pval'], (df['-log10_pval'].min(), df['-log10_pval'].max()), (40, 250))\n",
    "\n",
    "# 6. Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(df['rank'], df['score'], c=colors, s=sizes, alpha=0.85, edgecolor='k', linewidth=0.5, zorder=3)\n",
    "\n",
    "# 7. BALANCED LABELS - With sufficient separation to avoid overlaps\n",
    "# Separate depleted and enriched genes\n",
    "depleted_genes = []\n",
    "enriched_genes = []\n",
    "\n",
    "for idx in idx_to_label:\n",
    "    row = df.loc[idx]\n",
    "    if row['score'] < 0:\n",
    "        depleted_genes.append((idx, row))\n",
    "    else:\n",
    "        enriched_genes.append((idx, row))\n",
    "\n",
    "# Sort for better distribution\n",
    "depleted_genes.sort(key=lambda x: x[1]['score'])\n",
    "# Enriched genes will be sorted in the labeling section to avoid crossings\n",
    "\n",
    "# Labels for DEPLETED genes (to the RIGHT of each point)\n",
    "for i, (idx, row) in enumerate(depleted_genes):\n",
    "    point_x = row['rank']\n",
    "    point_y = row['score']\n",
    "    \n",
    "    # Label position: 6% of width to the right + slight vertical offset\n",
    "    label_x = point_x + len(df) * 0.06  # 6% of total width\n",
    "    label_y = point_y + (i - len(depleted_genes)/2) * 0.05  # Vertical separation\n",
    "    \n",
    "    plt.annotate(row['gene'], \n",
    "                xy=(point_x, point_y),  # Point where it points\n",
    "                xytext=(label_x, label_y),  # Text position\n",
    "                fontsize=9, fontweight='bold', color='#1f77b4',\n",
    "                ha='left', va='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.25', \n",
    "                         facecolor='white', \n",
    "                         edgecolor='#1f77b4', \n",
    "                         alpha=0.85,\n",
    "                         linewidth=1),\n",
    "                arrowprops=dict(arrowstyle='->', \n",
    "                               color='#1f77b4', \n",
    "                               lw=1.0, \n",
    "                               alpha=0.7,\n",
    "                               shrinkA=3,    # More space from text\n",
    "                               shrinkB=8),   # Distance to point\n",
    "                zorder=10)\n",
    "\n",
    "# Labels for ENRICHED genes (to the LEFT of each point)\n",
    "# Sort by descending score so highest labels are on top and arrows don't cross\n",
    "enriched_genes_sorted = sorted(enriched_genes, key=lambda x: x[1]['score'], reverse=True)\n",
    "\n",
    "for i, (idx, row) in enumerate(enriched_genes_sorted):\n",
    "    point_x = row['rank']\n",
    "    point_y = row['score']\n",
    "    \n",
    "    # Label position: LONGER ARROWS - 12% of width to the left + progressive vertical separation\n",
    "    label_x = point_x - len(df) * 0.12  # 12% of total width (longer arrows)\n",
    "    \n",
    "    # Progressive vertical separation: highest labels go higher\n",
    "    base_y = max([r[1]['score'] for r in enriched_genes]) + 0.1  # Base from highest score\n",
    "    label_y = base_y - (i * 0.08)  # Vertical separation of 0.08 between labels\n",
    "    \n",
    "    plt.annotate(row['gene'], \n",
    "                xy=(point_x, point_y),  # Point where it points\n",
    "                xytext=(label_x, label_y),  # Text position\n",
    "                fontsize=9, fontweight='bold', color='#d62728',\n",
    "                ha='right', va='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.25', \n",
    "                         facecolor='white', \n",
    "                         edgecolor='#d62728', \n",
    "                         alpha=0.85,\n",
    "                         linewidth=1),\n",
    "                arrowprops=dict(arrowstyle='->', \n",
    "                               color='#d62728', \n",
    "                               lw=1.2,      # Slightly thicker arrows\n",
    "                               alpha=0.8,   # Slightly more opaque\n",
    "                               shrinkA=3,   # Space from text\n",
    "                               shrinkB=8),  # Distance to point\n",
    "                zorder=10)\n",
    "\n",
    "# 8. Final aesthetics\n",
    "plt.axhline(0, color='black', linewidth=0.8, zorder=1)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Phenotype score', fontsize=12)\n",
    "plt.title('Ranked phenotype score plot PatuS', fontsize=14, pad=10)\n",
    "\n",
    "# 9. Gene color legend (positioned to not overlap the plot)\n",
    "from matplotlib.patches import Patch\n",
    "color_legend = [\n",
    "    Patch(facecolor='#d62728', alpha=0.8, label='Enriched genes (red)'),\n",
    "    Patch(facecolor='#1f77b4', alpha=0.8, label='Depleted genes (blue)')\n",
    "]\n",
    "\n",
    "# Color legend at the top\n",
    "legend1 = plt.legend(handles=color_legend, \n",
    "                    loc='upper center', \n",
    "                    bbox_to_anchor=(0.5, 0.95),\n",
    "                    ncol=2,\n",
    "                    frameon=True, \n",
    "                    fancybox=True, \n",
    "                    shadow=True,\n",
    "                    fontsize=11)\n",
    "\n",
    "# 10. Point size legend (p-value) in the bottom right corner\n",
    "legend_elements_pval = []\n",
    "for pval in [0.05, 0.01, 0.001]:\n",
    "    size = np.interp(-np.log10(pval), (df['-log10_pval'].min(), df['-log10_pval'].max()), (40, 250))\n",
    "    legend_elements_pval.append(plt.scatter([], [], c='gray', alpha=0.5, s=size, label=f'p = {pval}'))\n",
    "\n",
    "legend2 = plt.legend(handles=legend_elements_pval,\n",
    "                    scatterpoints=1, \n",
    "                    frameon=False, \n",
    "                    labelspacing=1, \n",
    "                    title='P-value', \n",
    "                    loc='lower right')\n",
    "\n",
    "# Add both legends\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\n=== BALANCED PLOT ===\")\n",
    "print(f\"🔴 Enriched genes: {len(enriched_genes)} (left labels with long arrows)\")\n",
    "print(f\"🔵 Depleted genes: {len(depleted_genes)} (right labels)\")\n",
    "print(f\"✨ Long arrows and ordered labels to avoid crossings and overlaps\")\n",
    "print(f\"📊 Total points: {len(df)}\")\n",
    "\n",
    "print(f\"\\nEnriched genes (red - left labels, ordered without crossings):\")\n",
    "for _, (idx, row) in enumerate(enriched_genes_sorted):\n",
    "    print(f\"  🔴 {row['gene']}: {row['score']:.3f}\")\n",
    "\n",
    "print(f\"\\nDepleted genes (blue - right labels):\")\n",
    "for _, (idx, row) in enumerate(depleted_genes):\n",
    "    print(f\"  🔵 {row['gene']}: {row['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a4777",
   "metadata": {},
   "source": [
    "<H5> PATUT CORREGIDO POR CNV ANNDATA<H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from screenpro.phenoscore import runPhenoScore\n",
    "\n",
    "result_name, result_df_patuT_CNV = runPhenoScore(\n",
    "    adata=patuT_CNV_adata,\n",
    "    cond_ref=\"control\",\n",
    "    cond_test=\"treated\",\n",
    "    score_level=\"compare_reps\",\n",
    "    var_names=\"target\",\n",
    "    test=\"ttest\",\n",
    "    ctrl_label=\"negative_control\"\n",
    ")\n",
    "\n",
    "# Mostrar los primeros resultados obtenidos\n",
    "print(f\"Resultados guardados bajo el nombre: {result_name}\")\n",
    "print(result_df_patuT_CNV.head())\n",
    "\n",
    "# Filtrar e imprimir todos los resultados significativos (BH adj_pvalue <= 0.05)\n",
    "significativos = result_df_patuT_CNV[result_df_patuT_CNV[\"BH adj_pvalue\"] <= 0.05]\n",
    "print(f\"Resultados significativos (BH adj_pvalue <= 0.05): {len(significativos)}\")\n",
    "print(significativos)\n",
    "\n",
    "# Volcano plot para result_df_patuS (score vs. -log10(BH adj_pvalue)), resaltando sgRNAs con |score| ≥ 0.15 y BH adj_pvalue < 0.05\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "df = result_df_patuT_CNV.copy()\n",
    "df['-log10_BH_adj_pvalue'] = -np.log10(df['BH adj_pvalue'])\n",
    "is_significant = (df['BH adj_pvalue'] < 0.05) & (np.abs(df['score']) >= 0.15)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.scatter(df['score'], df['-log10_BH_adj_pvalue'], c='grey', alpha=0.5, label='Not significant')\n",
    "plt.scatter(df[is_significant]['score'], df[is_significant]['-log10_BH_adj_pvalue'],\n",
    "            c='red', alpha=0.8, label='Significant (|score| ≥ 0.15 & BH adj_pvalue < 0.05)')\n",
    "\n",
    "# Etiquetas bonitas con adjustText\n",
    "texts = []\n",
    "for _, row in df[is_significant].iterrows():\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['score'], row['-log10_BH_adj_pvalue'],\n",
    "            str(row['target']),\n",
    "            fontsize=10, color='black', weight='bold',\n",
    "            bbox=dict(facecolor='white', edgecolor='red', boxstyle='round,pad=0.2'),\n",
    "            ha='left', va='center'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Ajustar las etiquetas para que no se salgan ni se solapen\n",
    "adjust_text(\n",
    "    texts,\n",
    "    only_move={'points':'y', 'texts':'y'},  # Solo mover en vertical\n",
    "    arrowprops=dict(arrowstyle='-', color='red', lw=1)\n",
    ")\n",
    "\n",
    "plt.axvline(x=0.15, color='blue', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=-0.15, color='blue', linestyle='--', linewidth=1)\n",
    "plt.axhline(y=-np.log10(0.05), color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('-log10(BH adj_pvalue)')\n",
    "plt.title('Volcano plot PatuT')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ranked phenotype score plot for PatuT corrected by CNV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# 1. Prepare data\n",
    "df = result_df_patuT_CNV.copy()\n",
    "df = df.dropna(subset=['score', 'BH adj_pvalue'])\n",
    "df['gene'] = df['target'].str.split('--?>').str[0].str.strip()\n",
    "df['-log10_pval'] = -np.log10(np.clip(df['BH adj_pvalue'], 1e-300, 1))\n",
    "\n",
    "# 2. Sort by score for global ranking\n",
    "df = df.sort_values('score')\n",
    "df = df.reset_index(drop=True)\n",
    "df['rank'] = np.arange(1, len(df)+1)\n",
    "\n",
    "# 3. Find lowest and highest score for each gene\n",
    "idx_min = df.groupby('gene')['score'].idxmin()\n",
    "idx_max = df.groupby('gene')['score'].idxmax()\n",
    "extremos = pd.concat([df.loc[idx_min], df.loc[idx_max]]).drop_duplicates()\n",
    "\n",
    "# 4. Select 10 depleted genes and 6 enriched genes\n",
    "top_depleted = extremos.nsmallest(10, 'score')  # 10 depleted\n",
    "top_enriched = extremos.nlargest(6, 'score')   # 6 enriched\n",
    "idx_to_label = set(top_depleted.index).union(set(top_enriched.index))\n",
    "\n",
    "# 5. Color and size\n",
    "colors = np.where(df['score'] < 0, '#1f77b4', '#d62728')\n",
    "sizes = np.interp(df['-log10_pval'], (df['-log10_pval'].min(), df['-log10_pval'].max()), (40, 250))\n",
    "\n",
    "# 6. Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(df['rank'], df['score'], c=colors, s=sizes, alpha=0.85, edgecolor='k', linewidth=0.5, zorder=3)\n",
    "\n",
    "# 7. BALANCED LABELS - With sufficient separation to avoid overlaps\n",
    "# Separate depleted and enriched genes\n",
    "depleted_genes = []\n",
    "enriched_genes = []\n",
    "\n",
    "for idx in idx_to_label:\n",
    "    row = df.loc[idx]\n",
    "    if row['score'] < 0:\n",
    "        depleted_genes.append((idx, row))\n",
    "    else:\n",
    "        enriched_genes.append((idx, row))\n",
    "\n",
    "# Sort for better distribution\n",
    "depleted_genes.sort(key=lambda x: x[1]['score'])\n",
    "# Enriched genes will be sorted in the labeling section to avoid crossings\n",
    "\n",
    "# Labels for DEPLETED genes (to the RIGHT of each point)\n",
    "for i, (idx, row) in enumerate(depleted_genes):\n",
    "    point_x = row['rank']\n",
    "    point_y = row['score']\n",
    "    \n",
    "    # Label position: 6% of width to the right + slight vertical offset\n",
    "    label_x = point_x + len(df) * 0.06  # 6% of total width\n",
    "    label_y = point_y + (i - len(depleted_genes)/2) * 0.05  # Vertical separation\n",
    "    \n",
    "    plt.annotate(row['gene'], \n",
    "                xy=(point_x, point_y),  # Point where it points\n",
    "                xytext=(label_x, label_y),  # Text position\n",
    "                fontsize=9, fontweight='bold', color='#1f77b4',\n",
    "                ha='left', va='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.25', \n",
    "                         facecolor='white', \n",
    "                         edgecolor='#1f77b4', \n",
    "                         alpha=0.85,\n",
    "                         linewidth=1),\n",
    "                arrowprops=dict(arrowstyle='->', \n",
    "                               color='#1f77b4', \n",
    "                               lw=1.0, \n",
    "                               alpha=0.7,\n",
    "                               shrinkA=3,    # More space from text\n",
    "                               shrinkB=8),   # Distance to point\n",
    "                zorder=10)\n",
    "\n",
    "# Labels for ENRICHED genes (to the LEFT of each point)\n",
    "# Sort by descending score so highest labels are on top and arrows don't cross\n",
    "enriched_genes_sorted = sorted(enriched_genes, key=lambda x: x[1]['score'], reverse=True)\n",
    "\n",
    "for i, (idx, row) in enumerate(enriched_genes_sorted):\n",
    "    point_x = row['rank']\n",
    "    point_y = row['score']\n",
    "    \n",
    "    # Label position: LONGER ARROWS - 12% of width to the left + progressive vertical separation\n",
    "    label_x = point_x - len(df) * 0.12  # 12% of total width (longer arrows)\n",
    "    \n",
    "    # Progressive vertical separation: highest labels go higher\n",
    "    base_y = max([r[1]['score'] for r in enriched_genes]) + 0.1  # Base from highest score\n",
    "    label_y = base_y - (i * 0.08)  # Vertical separation of 0.08 between labels\n",
    "    \n",
    "    plt.annotate(row['gene'], \n",
    "                xy=(point_x, point_y),  # Point where it points\n",
    "                xytext=(label_x, label_y),  # Text position\n",
    "                fontsize=9, fontweight='bold', color='#d62728',\n",
    "                ha='right', va='center',\n",
    "                bbox=dict(boxstyle='round,pad=0.25', \n",
    "                         facecolor='white', \n",
    "                         edgecolor='#d62728', \n",
    "                         alpha=0.85,\n",
    "                         linewidth=1),\n",
    "                arrowprops=dict(arrowstyle='->', \n",
    "                               color='#d62728', \n",
    "                               lw=1.2,      # Slightly thicker arrows\n",
    "                               alpha=0.8,   # Slightly more opaque\n",
    "                               shrinkA=3,   # Space from text\n",
    "                               shrinkB=8),  # Distance to point\n",
    "                zorder=10)\n",
    "\n",
    "# 8. Final aesthetics\n",
    "plt.axhline(0, color='black', linewidth=0.8, zorder=1)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Phenotype score', fontsize=12)\n",
    "plt.title('Ranked phenotype score plot PatuT', fontsize=14, pad=10)\n",
    "\n",
    "# 9. Gene color legend (positioned to not overlap the plot)\n",
    "from matplotlib.patches import Patch\n",
    "color_legend = [\n",
    "    Patch(facecolor='#d62728', alpha=0.8, label='Enriched genes (red)'),\n",
    "    Patch(facecolor='#1f77b4', alpha=0.8, label='Depleted genes (blue)')\n",
    "]\n",
    "\n",
    "# Color legend at the top\n",
    "legend1 = plt.legend(handles=color_legend, \n",
    "                    loc='upper center', \n",
    "                    bbox_to_anchor=(0.5, 0.95),\n",
    "                    ncol=2,\n",
    "                    frameon=True, \n",
    "                    fancybox=True, \n",
    "                    shadow=True,\n",
    "                    fontsize=11)\n",
    "\n",
    "# 10. Point size legend (p-value) in the bottom right corner\n",
    "legend_elements_pval = []\n",
    "for pval in [0.05, 0.01, 0.001]:\n",
    "    size = np.interp(-np.log10(pval), (df['-log10_pval'].min(), df['-log10_pval'].max()), (40, 250))\n",
    "    legend_elements_pval.append(plt.scatter([], [], c='gray', alpha=0.5, s=size, label=f'p = {pval}'))\n",
    "\n",
    "legend2 = plt.legend(handles=legend_elements_pval,\n",
    "                    scatterpoints=1, \n",
    "                    frameon=False, \n",
    "                    labelspacing=1, \n",
    "                    title='P-value', \n",
    "                    loc='lower right')\n",
    "\n",
    "# Add both legends\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\n=== BALANCED PLOT ===\")\n",
    "print(f\"🔴 Enriched genes: {len(enriched_genes)} (left labels with long arrows)\")\n",
    "print(f\"🔵 Depleted genes: {len(depleted_genes)} (right labels)\")\n",
    "print(f\"✨ Long arrows and ordered labels to avoid crossings and overlaps\")\n",
    "print(f\"📊 Total points: {len(df)}\")\n",
    "\n",
    "print(f\"\\nEnriched genes (red - left labels, ordered without crossings):\")\n",
    "for _, (idx, row) in enumerate(enriched_genes_sorted):\n",
    "    print(f\"  🔴 {row['gene']}: {row['score']:.3f}\")\n",
    "\n",
    "print(f\"\\nDepleted genes (blue - right labels):\")\n",
    "for _, (idx, row) in enumerate(depleted_genes):\n",
    "    print(f\"  🔵 {row['gene']}: {row['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c70c28",
   "metadata": {},
   "source": [
    "<H5> PATUS mageckcount CORREGIDO POR CNV ANNDATA<H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128670c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from screenpro.phenoscore import runPhenoScore\n",
    "\n",
    "result_name, result_df_patuS_mageck_CNV = runPhenoScore(\n",
    "    adata=patuS_mageck_CNV_adata,\n",
    "    cond_ref=\"control\",\n",
    "    cond_test=\"treated\",\n",
    "    score_level=\"compare_reps\",\n",
    "    var_names=\"target\",\n",
    "    test=\"ttest\",\n",
    "    ctrl_label=\"negative_control\"\n",
    ")\n",
    "\n",
    "# Mostrar los primeros resultados obtenidos\n",
    "print(f\"Resultados guardados bajo el nombre: {result_name}\")\n",
    "print(result_df_patuS_mageck_CNV.head())\n",
    "\n",
    "# Filtrar e imprimir todos los resultados significativos (BH adj_pvalue <= 0.05)\n",
    "significativos = result_df_patuS_mageck_CNV[result_df_patuS_mageck_CNV[\"BH adj_pvalue\"] <= 0.05]\n",
    "print(f\"Resultados significativos (BH adj_pvalue <= 0.05): {len(significativos)}\")\n",
    "print(significativos)\n",
    "\n",
    "# Volcano plot para result_df_patuS (score vs. -log10(ttest pvalue)), resaltando sgRNAs con |score| ≥ 0.15 y ttest pvalue < 0.05\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "df = result_df_patuS_mageck_CNV.copy()\n",
    "df['-log10_ttest_pvalue'] = -np.log10(df['ttest pvalue'])\n",
    "is_significant = (df['ttest pvalue'] < 0.05) & (np.abs(df['score']) >= 0.15)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.scatter(df['score'], df['-log10_ttest_pvalue'], c='grey', alpha=0.5, label='No significativo')\n",
    "plt.scatter(df[is_significant]['score'], df[is_significant]['-log10_ttest_pvalue'],\n",
    "            c='red', alpha=0.8, label='Significativo (|score| ≥ 0.15 y ttest pvalue < 0.05)')\n",
    "\n",
    "# Etiquetas bonitas con adjustText\n",
    "texts = []\n",
    "for _, row in df[is_significant].iterrows():\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['score'], row['-log10_ttest_pvalue'],\n",
    "            str(row['target']),\n",
    "            fontsize=10, color='black', weight='bold',\n",
    "            bbox=dict(facecolor='white', edgecolor='red', boxstyle='round,pad=0.2'),\n",
    "            ha='left', va='center'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Ajustar las etiquetas para que no se salgan ni se solapen\n",
    "adjust_text(\n",
    "    texts,\n",
    "    only_move={'points':'y', 'texts':'y'},  # Solo mover en vertical\n",
    "    arrowprops=dict(arrowstyle='-', color='red', lw=1)\n",
    ")\n",
    "\n",
    "plt.axvline(x=0.15, color='blue', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=-0.15, color='blue', linestyle='--', linewidth=1)\n",
    "plt.axhline(y=-np.log10(0.05), color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('-log10(ttest pvalue)')\n",
    "plt.title('Volcano plot: Score vs. Significancia por sgRNA (PatuS mageckcount corregido por CNV)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b9863",
   "metadata": {},
   "source": [
    "<H5> PATUT mageckcount CORREGIDO POR CNV ANNDATA<H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ca6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from screenpro.phenoscore import runPhenoScore\n",
    "\n",
    "result_name, result_df_patuT_mageck_CNV = runPhenoScore(\n",
    "    adata=patuT_mageck_CNV_adata,\n",
    "    cond_ref=\"control\",\n",
    "    cond_test=\"treated\",\n",
    "    score_level=\"compare_reps\",\n",
    "    var_names=\"target\",\n",
    "    test=\"ttest\",\n",
    "    ctrl_label=\"negative_control\"\n",
    ")\n",
    "\n",
    "# Mostrar los primeros resultados obtenidos\n",
    "print(f\"Resultados guardados bajo el nombre: {result_name}\")\n",
    "print(result_df_patuT_mageck_CNV.head())\n",
    "\n",
    "# Filtrar e imprimir todos los resultados significativos (BH adj_pvalue <= 0.05)\n",
    "significativos = result_df_patuT_mageck_CNV[result_df_patuT_mageck_CNV[\"BH adj_pvalue\"] <= 0.05]\n",
    "print(f\"Resultados significativos (BH adj_pvalue <= 0.05): {len(significativos)}\")\n",
    "print(significativos)\n",
    "\n",
    "# Volcano plot para result_df_patuS (score vs. -log10(BH adj_pvalue)), resaltando sgRNAs con |score| ≥ 0.15 y BH adj_pvalue < 0.05\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "df = result_df_patuT_mageck_CNV.copy()\n",
    "df['-log10_BH_adj_pvalue'] = -np.log10(df['BH adj_pvalue'])\n",
    "is_significant = (df['BH adj_pvalue'] < 0.05) & (np.abs(df['score']) >= 0.15)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.scatter(df['score'], df['-log10_BH_adj_pvalue'], c='grey', alpha=0.5, label='No significativo')\n",
    "plt.scatter(df[is_significant]['score'], df[is_significant]['-log10_BH_adj_pvalue'],\n",
    "            c='red', alpha=0.8, label='Significativo (|score| ≥ 0.15 y BH adj_pvalue < 0.05)')\n",
    "\n",
    "# Etiquetas bonitas con adjustText\n",
    "texts = []\n",
    "for _, row in df[is_significant].iterrows():\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['score'], row['-log10_BH_adj_pvalue'],\n",
    "            str(row['target']),\n",
    "            fontsize=10, color='black', weight='bold',\n",
    "            bbox=dict(facecolor='white', edgecolor='red', boxstyle='round,pad=0.2'),\n",
    "            ha='left', va='center'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Ajustar las etiquetas para que no se salgan ni se solapen\n",
    "adjust_text(\n",
    "    texts,\n",
    "    only_move={'points':'y', 'texts':'y'},  # Solo mover en vertical\n",
    "    arrowprops=dict(arrowstyle='-', color='red', lw=1)\n",
    ")\n",
    "\n",
    "plt.axvline(x=0.15, color='blue', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=-0.15, color='blue', linestyle='--', linewidth=1)\n",
    "plt.axhline(y=-np.log10(0.05), color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('-log10(BH adj_pvalue)')\n",
    "plt.title('Volcano plot: Score vs. Significancia por sgRNA (PatuS mageckcount corregido por CNV)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparación de counts entre los generados por el script #fastq_to_counts.py y los generados por mageckcount\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar counts de tu script (muestras en filas, sgRNAs en columnas)\n",
    "counts_script = pd.read_csv(r\"C:\\Users\\alvar\\Desktop\\TFM 12O\\csv2\\PatuS_X.tsv\", sep='\\t', index_col=0)\n",
    "\n",
    "# Cargar counts de mageck (sgRNAs en filas, muestras en columnas)\n",
    "counts_mageck = pd.read_csv(r\"TFM_12O\\02.Counts\\mageckcount\\all_samples_PatuS.count.txt\", sep='\\t', index_col=0)\n",
    "counts_mageck_T = counts_mageck.T  # Trasponer para que las muestras sean filas\n",
    "\n",
    "# Seleccionar la primera muestra (ajusta el nombre si es necesario)\n",
    "sample_name = counts_script.index[20]\n",
    "first_sample_script = counts_script.loc[sample_name]\n",
    "first_sample_mageck = counts_mageck_T.loc[sample_name]\n",
    "\n",
    "# Limpiar índices de posibles espacios, BOM y duplicados\n",
    "first_sample_script.index = first_sample_script.index.astype(str).str.strip().str.replace('\\ufeff', '', regex=False)\n",
    "first_sample_mageck.index = first_sample_mageck.index.astype(str).str.strip().str.replace('\\ufeff', '', regex=False)\n",
    "\n",
    "# Si hay duplicados, sumarlos\n",
    "first_sample_script = first_sample_script.groupby(first_sample_script.index).sum()\n",
    "first_sample_mageck = first_sample_mageck.groupby(first_sample_mageck.index).sum()\n",
    "\n",
    "# Alinear los sgRNAs por nombre\n",
    "df_compare = pd.DataFrame({\n",
    "    'count_script': first_sample_script,\n",
    "    'count_mageck': first_sample_mageck\n",
    "}).fillna(0)\n",
    "\n",
    "# Graficar en escala log-log\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(df_compare['count_script'] + 1, df_compare['count_mageck'] + 1, alpha=0.6)\n",
    "plt.plot([1, df_compare['count_script'].max()+1], [1, df_compare['count_script'].max()+1], 'k--', alpha=0.7)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Counts (Script fastq_to_counts.py)')\n",
    "plt.ylabel('Counts (MAGeCK)')\n",
    "plt.title('Comparación de counts por sgRNA')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar sgRNAs con mayores diferencias absolutas\n",
    "df_compare['abs_diff'] = np.abs(df_compare['count_script'] - df_compare['count_mageck'])\n",
    "top_diff = df_compare.sort_values('abs_diff', ascending=False).head(10)\n",
    "print(\"sgRNAs con mayores diferencias absolutas:\")\n",
    "print(top_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a35dd",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "Referencia 2: Inactivation of the Euchromatic Histone-Lysine N-Methyltransferase G9a Attenuates Oncogenic KRAS-Driven Pancreatic Cancer (PMC8261250)\n",
    "\n",
    "Referencia 4: Smarcd3 is an epigenetic modulator of the metabolic landscape in pancreatic cancer (PMC9849267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of EHMT2 and PRMT7 sgRNAs in PatuT CNV corrected data\n",
    "# Show score and statistical significance for all sgRNAs targeting EHMT2 and PRMT7\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Filter sgRNAs containing EHMT2 or PRMT7 in their target name\n",
    "ehmt2_prmt7_sgrnas = result_df_patuT_CNV[\n",
    "    result_df_patuT_CNV['target'].str.contains('EHMT2|PRMT7', case=False, na=False)\n",
    "].copy()\n",
    "\n",
    "# Select relevant columns: target, score, ttest pvalue, BH adj_pvalue\n",
    "ehmt2_prmt7_results = ehmt2_prmt7_sgrnas[['target', 'score', 'ttest pvalue', 'BH adj_pvalue']].copy()\n",
    "\n",
    "# Sort by score (from most depleted to most enriched)\n",
    "ehmt2_prmt7_results = ehmt2_prmt7_results.sort_values('score')\n",
    "\n",
    "print(\"=== EHMT2 and PRMT7 sgRNAs Analysis ===\")\n",
    "print(f\"Total sgRNAs found: {len(ehmt2_prmt7_results)}\")\n",
    "print(\"\\nResults (sorted by score):\")\n",
    "print(ehmt2_prmt7_results.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== Summary ===\")\n",
    "print(f\"EHMT2 sgRNAs: {len(ehmt2_prmt7_results[ehmt2_prmt7_results['target'].str.contains('EHMT2', case=False)])}\")\n",
    "print(f\"PRMT7 sgRNAs: {len(ehmt2_prmt7_results[ehmt2_prmt7_results['target'].str.contains('PRMT7', case=False)])}\")\n",
    "\n",
    "# Significant sgRNAs (ttest pvalue < 0.05)\n",
    "significant_ttest = ehmt2_prmt7_results[ehmt2_prmt7_results['ttest pvalue'] < 0.05]\n",
    "print(f\"Significant by ttest pvalue (< 0.05): {len(significant_ttest)}\")\n",
    "\n",
    "# Significant sgRNAs (BH adj_pvalue < 0.05)\n",
    "significant_bh = ehmt2_prmt7_results[ehmt2_prmt7_results['BH adj_pvalue'] < 0.05]\n",
    "print(f\"Significant by BH adj_pvalue (< 0.05): {len(significant_bh)}\")\n",
    "\n",
    "if len(significant_ttest) > 0:\n",
    "    print(f\"\\nSignificant sgRNAs (ttest pvalue < 0.05):\")\n",
    "    print(significant_ttest.to_string(index=False))\n",
    "\n",
    "if len(significant_bh) > 0:\n",
    "    print(f\"\\nSignificant sgRNAs (BH adj_pvalue < 0.05):\")\n",
    "    print(significant_bh.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
